#!/usr/bin/env python3
"""
√úbung 01: CSV Import Basics

Lernziele:
- CSV-Dateien mit verschiedenen Trennzeichen importieren
- Datentypen korrekt erkennen und konvertieren
- Fehlende Werte behandeln
- Basis-Validierung implementieren

Schwierigkeitsgrad: ‚≠ê‚≠ê‚òÜ‚òÜ
Gesch√§tzte Zeit: 30-45 Minuten
"""

from pathlib import Path

import numpy as np
import pandas as pd


def get_data_path(*args):
    """
    Hilfsfunktion zum korrekten Konstruieren der Datenpfade
    """
    project_root = Path(__file__).parent.parent.parent.parent
    data_path = project_root / "data"
    for arg in args:
        data_path = data_path / arg
    return data_path


def setup_test_data():
    """
    Erstellt Testdaten f√ºr die √úbungen
    """
    print("üèóÔ∏è Erstelle Testdaten f√ºr CSV-√úbungen...")

    # Testdaten-Verzeichnis erstellen
    test_dir = get_data_path("uebungen", "csv_basics")
    test_dir.mkdir(parents=True, exist_ok=True)

    # 1. Standard CSV mit Komma
    standard_data = {
        "Datum": pd.date_range("2024-01-01", periods=50),
        "Maschine": np.random.choice(["Alpha", "Beta", "Gamma"], 50),
        "Produktion": np.random.randint(500, 1500, 50),
        "Temperatur": np.round(np.random.normal(23, 3, 50), 1),
        "Status": np.random.choice(["OK", "WARNING", "ERROR"], 50, p=[0.7, 0.2, 0.1]),
    }
    df_standard = pd.DataFrame(standard_data)
    df_standard.to_csv(test_dir / "standard_data.csv", index=False)

    # 2. CSV mit Semikolon und deutschen Dezimaltrennern
    german_data = df_standard.copy()
    german_file = test_dir / "german_format.csv"
    german_data.to_csv(german_file, index=False, sep=";", decimal=",")

    # 3. CSV mit Tab-Trennung
    tab_file = test_dir / "tab_separated.csv"
    df_standard.to_csv(tab_file, index=False, sep="\t")

    # 4. CSV mit fehlenden Werten
    missing_data = df_standard.copy()
    # Zuf√§llig einige Werte auf NaN setzen
    missing_indices = np.random.choice(len(missing_data), size=15, replace=False)
    missing_data.loc[missing_indices, "Produktion"] = np.nan
    missing_indices = np.random.choice(len(missing_data), size=8, replace=False)
    missing_data.loc[missing_indices, "Temperatur"] = np.nan
    missing_data.to_csv(test_dir / "data_with_missing.csv", index=False)

    # 5. Problematische CSV mit inkonsistenten Daten
    problematic_data = """Maschine;Produktion;Temperatur;Verfuegbarkeit
Alpha;1000;22.5;95.0
Beta;;23.1;88.5
Gamma;1200;-999;92.0
Delta;800;24.2;
Alpha;1500;25.8;120.5
Beta;FEHLER;21.3;85.2
Gamma;900;0;75.0"""

    with open(test_dir / "problematic_data.csv", "w") as f:
        f.write(problematic_data)

    print(f"‚úÖ Testdaten erstellt in: {test_dir}")
    return test_dir


# =============================================================================
# AUFGABEN - L√∂sen Sie die folgenden √úbungen
# =============================================================================


def aufgabe_1_grundlegender_import():
    """
    AUFGABE 1: Grundlegender CSV-Import (‚≠ê‚≠ê‚òÜ‚òÜ)

    TODO: Implementieren Sie eine Funktion, die:
    1. Die Datei 'standard_data.csv' importiert
    2. Die ersten und letzten 3 Zeilen anzeigt
    3. Die Datentypen aller Spalten ausgibt
    4. Die Dimensionen (Zeilen √ó Spalten) anzeigt

    Tipps:
    - Verwenden Sie pd.read_csv()
    - Nutzen Sie .head() und .tail() f√ºr die Anzeige
    - .dtypes zeigt die Datentypen
    - .shape gibt die Dimensionen zur√ºck
    """
    print("\n" + "=" * 50)
    print("üìù AUFGABE 1: Grundlegender CSV-Import")
    print("=" * 50)

    # TODO: Ihren Code hier einf√ºgen

    # Laden Sie die CSV-Datei
    csv_file = get_data_path("uebungen", "csv_basics", "standard_data.csv")

    # L√ñSUNG VERSTECKT - Entfernen Sie diese Kommentare f√ºr die Musterl√∂sung:
    """
    df = pd.read_csv(csv_file)

    print(f"üìä Dataset geladen: {df.shape[0]} Zeilen √ó {df.shape[1]} Spalten")

    print("\\nüîº Erste 3 Zeilen:")
    print(df.head(3))

    print("\\nüîΩ Letzte 3 Zeilen:")
    print(df.tail(3))

    print("\\nüìã Datentypen:")
    print(df.dtypes)

    return df
    """

    # Ihre Implementierung:
    pass  # Ersetzen Sie 'pass' durch Ihren Code


def aufgabe_2_verschiedene_trennzeichen():
    """
    AUFGABE 2: Verschiedene Trennzeichen handhaben (‚≠ê‚≠ê‚òÜ‚òÜ)

    TODO: Implementieren Sie eine Funktion, die:
    1. Alle CSV-Dateien mit verschiedenen Trennzeichen l√§dt:
       - german_format.csv (Semikolon, Komma als Dezimaltrenner)
       - tab_separated.csv (Tab-getrennt)
    2. √úberpr√ºft, ob alle DataFrames identische Inhalte haben
    3. Die verwendeten Trennzeichen dokumentiert

    Tipps:
    - Parameter 'sep' f√ºr Trennzeichen
    - Parameter 'decimal' f√ºr Dezimaltrenner
    - Verwenden Sie .equals() zum Vergleichen von DataFrames
    """
    print("\n" + "=" * 50)
    print("üìù AUFGABE 2: Verschiedene Trennzeichen")
    print("=" * 50)

    # TODO: Ihren Code hier einf√ºgen

    # L√ñSUNG VERSTECKT:
    """
    files_and_params = [
        (get_data_path("uebungen", "csv_basics", "standard_data.csv"), ',', '.'),
        (get_data_path("uebungen", "csv_basics", "german_format.csv"), ';', ','),
        (get_data_path("uebungen", "csv_basics", "tab_separated.csv"), '\\t', '.')
    ]

    dataframes = []

    for file_path, sep, decimal in files_and_params:
        df = pd.read_csv(file_path, sep=sep, decimal=decimal)
        dataframes.append((Path(file_path).name, df, sep, decimal))
        print(f"‚úÖ {Path(file_path).name} geladen (sep='{sep}', decimal='{decimal}'): {df.shape}")

    # Vergleiche alle DataFrames
    base_df = dataframes[0][1]
    for name, df, sep, decimal in dataframes[1:]:
        if base_df.equals(df):
            print(f"‚úÖ {name} ist identisch mit Standard-CSV")
        else:
            print(f"‚ùå {name} unterscheidet sich von Standard-CSV")

    return dataframes
    """

    # Ihre Implementierung:
    pass


def aufgabe_3_fehlende_werte_behandeln():
    """
    AUFGABE 3: Fehlende Werte erkennen und behandeln (‚≠ê‚≠ê‚≠ê‚òÜ)

    TODO: Implementieren Sie eine Funktion, die:
    1. Die Datei 'data_with_missing.csv' l√§dt
    2. Fehlende Werte pro Spalte z√§hlt und anzeigt
    3. Drei verschiedene Strategien zur Behandlung implementiert:
       - Zeilen mit fehlenden Werten entfernen
       - Fehlende Werte durch Durchschnitt ersetzen
       - Fehlende Werte durch Median ersetzen
    4. Die Ergebnisse aller Strategien vergleicht

    Tipps:
    - .isnull().sum() z√§hlt fehlende Werte
    - .dropna() entfernt Zeilen mit NaN
    - .fillna() ersetzt fehlende Werte
    - .mean() und .median() f√ºr Ersatzwerte
    """
    print("\n" + "=" * 50)
    print("üìù AUFGABE 3: Fehlende Werte behandeln")
    print("=" * 50)

    # TODO: Ihren Code hier einf√ºgen

    # L√ñSUNG VERSTECKT:
    """
    csv_file = get_data_path("uebungen", "csv_basics", "data_with_missing.csv")
    df_original = pd.read_csv(csv_file)

    print(f"üìä Original Dataset: {df_original.shape}")

    # Fehlende Werte analysieren
    missing_count = df_original.isnull().sum()
    print("\\n‚ùå Fehlende Werte pro Spalte:")
    for col, count in missing_count.items():
        if count > 0:
            percentage = (count / len(df_original)) * 100
            print(f"  {col}: {count} ({percentage:.1f}%)")

    # Strategie 1: Zeilen entfernen
    df_dropped = df_original.dropna()
    print(f"\\nüóëÔ∏è Nach dropna(): {df_dropped.shape[0]} Zeilen ({len(df_original) - len(df_dropped)} entfernt)")

    # Strategie 2: Durchschnitt
    df_mean_filled = df_original.copy()
    numeric_columns = df_original.select_dtypes(include=[np.number]).columns
    for col in numeric_columns:
        if col in missing_count and missing_count[col] > 0:
            mean_value = df_original[col].mean()
            df_mean_filled[col].fillna(mean_value, inplace=True)
            print(f"‚úÖ {col}: Fehlende Werte durch Durchschnitt ersetzt ({mean_value:.2f})")

    # Strategie 3: Median
    df_median_filled = df_original.copy()
    for col in numeric_columns:
        if col in missing_count and missing_count[col] > 0:
            median_value = df_original[col].median()
            df_median_filled[col].fillna(median_value, inplace=True)
            print(f"‚úÖ {col}: Fehlende Werte durch Median ersetzt ({median_value:.2f})")

    # Vergleich der Strategien
    strategies = {
        'Original': df_original,
        'Dropped': df_dropped,
        'Mean Filled': df_mean_filled,
        'Median Filled': df_median_filled
    }

    print("\\nüìä Strategien-Vergleich:")
    for name, df in strategies.items():
        missing = df.isnull().sum().sum()
        print(f"  {name}: {df.shape[0]} Zeilen, {missing} fehlende Werte")

    return strategies
    """

    # Ihre Implementierung:
    pass


def aufgabe_4_datenvalidierung():
    """
    AUFGABE 4: Datenvalidierung implementieren (‚≠ê‚≠ê‚≠ê‚≠ê)

    TODO: Implementieren Sie eine Funktion, die:
    1. Die Datei 'problematic_data.csv' l√§dt
    2. Datenqualit√§tsprobleme erkennt und behebt:
       - Negative Temperaturen (< -50¬∞C als unrealistisch markieren)
       - Verf√ºgbarkeit > 100% korrigieren
       - Nicht-numerische Produktionswerte behandeln
       - Leere Strings in numerischen Spalten
    3. Einen Validierungsbericht erstellt
    4. Die bereinigten Daten exportiert

    Tipps:
    - pd.to_numeric() mit errors='coerce' f√ºr robuste Konvertierung
    - Boolesche Indexierung f√ºr Datenfilterung
    - .describe() f√ºr statistische √úbersicht
    """
    print("\n" + "=" * 50)
    print("üìù AUFGABE 4: Datenvalidierung")
    print("=" * 50)

    # TODO: Ihren Code hier einf√ºgen

    # L√ñSUNG VERSTECKT:
    """
    csv_file = get_data_path("uebungen", "csv_basics", "problematic_data.csv")
    df_raw = pd.read_csv(csv_file, sep=';')

    print(f"üìä Rohdaten geladen: {df_raw.shape}")
    print("\\nüîç Rohdaten (erste 5 Zeilen):")
    print(df_raw.head())

    # Validierungsbericht initialisieren
    validation_report = {
        'issues_found': [],
        'fixes_applied': [],
        'original_rows': len(df_raw),
        'final_rows': 0
    }

    df_clean = df_raw.copy()

    # Problem 1: Produktionswerte bereinigen
    print("\\nüîß Bereinige Produktionswerte...")
    df_clean['Produktion'] = pd.to_numeric(df_clean['Produktion'], errors='coerce')
    production_issues = df_raw[df_raw['Produktion'].str.contains('FEHLER', na=False)]
    if not production_issues.empty:
        validation_report['issues_found'].append(f"Nicht-numerische Produktionswerte: {len(production_issues)}")
        validation_report['fixes_applied'].append("Konvertierung zu NaN f√ºr weitere Behandlung")

    # Problem 2: Unrealistische Temperaturen
    print("üå°Ô∏è Pr√ºfe Temperaturwerte...")
    df_clean['Temperatur'] = pd.to_numeric(df_clean['Temperatur'], errors='coerce')
    unrealistic_temp = df_clean['Temperatur'] < -50
    if unrealistic_temp.sum() > 0:
        validation_report['issues_found'].append(f"Unrealistische Temperaturen: {unrealistic_temp.sum()}")
        df_clean.loc[unrealistic_temp, 'Temperatur'] = np.nan
        validation_report['fixes_applied'].append("Unrealistische Temperaturen auf NaN gesetzt")

    # Problem 3: Verf√ºgbarkeit > 100%
    print("üìä Pr√ºfe Verf√ºgbarkeitsswerte...")
    df_clean['Verfuegbarkeit'] = pd.to_numeric(df_clean['Verfuegbarkeit'], errors='coerce')
    high_availability = df_clean['Verfuegbarkeit'] > 100
    if high_availability.sum() > 0:
        validation_report['issues_found'].append(f"Verf√ºgbarkeit > 100%: {high_availability.sum()}")
        df_clean.loc[high_availability, 'Verfuegbarkeit'] = 100.0
        validation_report['fixes_applied'].append("Verf√ºgbarkeit > 100% auf 100% korrigiert")

    # Problem 4: Fehlende Werte behandeln
    missing_before = df_clean.isnull().sum().sum()
    print(f"üîç Behandle fehlende Werte: {missing_before} gefunden")

    # Produktions-Mittelwert f√ºr fehlende Werte
    production_mean = df_clean['Produktion'].mean()
    df_clean['Produktion'].fillna(production_mean, inplace=True)

    # Verf√ºgbarkeits-Median f√ºr fehlende Werte
    availability_median = df_clean['Verfuegbarkeit'].median()
    df_clean['Verfuegbarkeit'].fillna(availability_median, inplace=True)

    missing_after = df_clean.isnull().sum().sum()
    validation_report['fixes_applied'].append(f"Fehlende Werte reduziert: {missing_before} ‚Üí {missing_after}")

    # Finale Statistiken
    validation_report['final_rows'] = len(df_clean)

    print("\\nüìã Validierungsbericht:")
    print(f"  Urspr√ºngliche Zeilen: {validation_report['original_rows']}")
    print(f"  Finale Zeilen: {validation_report['final_rows']}")
    print(f"  Gefundene Probleme: {len(validation_report['issues_found'])}")
    for issue in validation_report['issues_found']:
        print(f"    ‚Ä¢ {issue}")
    print(f"  Angewandte Korrekturen: {len(validation_report['fixes_applied'])}")
    for fix in validation_report['fixes_applied']:
        print(f"    ‚Ä¢ {fix}")

    # Bereinigte Daten exportieren
    output_file = get_data_path("uebungen", "csv_basics", "cleaned_data.csv")
    df_clean.to_csv(output_file, index=False)
    print(f"\\nüíæ Bereinigte Daten exportiert: {output_file}")

    print("\\nüìä Bereinigte Daten (√úbersicht):")
    print(df_clean.describe())

    return df_clean, validation_report
    """

    # Ihre Implementierung:
    pass


def aufgabe_5_visualisierung():
    """
    AUFGABE 5: CSV-Daten visualisieren (‚≠ê‚≠ê‚≠ê‚òÜ)

    TODO: Erstellen Sie Visualisierungen f√ºr die bereinigten Daten:
    1. Histogramm der Produktionsverteilung
    2. Boxplot der Temperatur nach Maschine
    3. Balkendiagramm der durchschnittlichen Verf√ºgbarkeit pro Maschine
    4. Zeitreihenplot der t√§glichen Gesamtproduktion

    Tipps:
    - Verwenden Sie matplotlib.pyplot
    - plt.subplots() f√ºr mehrere Plots
    - .hist(), .boxplot(), .bar() f√ºr verschiedene Diagrammtypen
    - .groupby() f√ºr Aggregationen
    """
    print("\n" + "=" * 50)
    print("üìù AUFGABE 5: Daten visualisieren")
    print("=" * 50)

    # Laden Sie die bereinigten Daten (falls verf√ºgbar)
    try:
        df_clean = pd.read_csv(
            get_data_path("uebungen", "csv_basics", "cleaned_data.csv")
        )
        print(f"‚úÖ Bereinigte Daten geladen: {df_clean.shape}")
    except FileNotFoundError:
        print("‚ö†Ô∏è Keine bereinigten Daten gefunden. Lade Standarddaten...")
        df_clean = pd.read_csv(
            get_data_path("uebungen", "csv_basics", "standard_data.csv")
        )

    # TODO: Ihren Code hier einf√ºgen

    # L√ñSUNG VERSTECKT:
    """
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('CSV-Daten Analyse Dashboard', fontsize=16)

    # Plot 1: Produktionsverteilung
    axes[0,0].hist(df_clean['Produktion'], bins=20, alpha=0.7, edgecolor='black')
    axes[0,0].set_title('Produktionsverteilung')
    axes[0,0].set_xlabel('Produktion (St√ºck)')
    axes[0,0].set_ylabel('H√§ufigkeit')
    axes[0,0].grid(True, alpha=0.3)

    # Plot 2: Temperatur nach Maschine
    machines = df_clean['Maschine'].unique()
    temp_data = [df_clean[df_clean['Maschine'] == machine]['Temperatur'].dropna() for machine in machines]

    axes[0,1].boxplot(temp_data, labels=machines)
    axes[0,1].set_title('Temperaturverteilung pro Maschine')
    axes[0,1].set_ylabel('Temperatur (¬∞C)')
    axes[0,1].grid(True, alpha=0.3)

    # Plot 3: Verf√ºgbarkeit pro Maschine
    if 'Verfuegbarkeit' in df_clean.columns:
        avg_availability = df_clean.groupby('Maschine')['Verfuegbarkeit'].mean()
        axes[1,0].bar(avg_availability.index, avg_availability.values, color='lightgreen', alpha=0.7)
        axes[1,0].set_title('Durchschnittliche Verf√ºgbarkeit pro Maschine')
        axes[1,0].set_ylabel('Verf√ºgbarkeit (%)')
        axes[1,0].grid(True, alpha=0.3)
    else:
        # Alternative: Status-Verteilung
        status_counts = df_clean['Status'].value_counts()
        axes[1,0].bar(status_counts.index, status_counts.values,
                      color=['green', 'orange', 'red'][:len(status_counts)])
        axes[1,0].set_title('Status-Verteilung')
        axes[1,0].set_ylabel('Anzahl')

    # Plot 4: Zeitreihe (falls Datum verf√ºgbar)
    if 'Datum' in df_clean.columns:
        df_clean['Datum'] = pd.to_datetime(df_clean['Datum'])
        daily_production = df_clean.groupby('Datum')['Produktion'].sum()

        axes[1,1].plot(daily_production.index, daily_production.values, 'b-', alpha=0.7)
        axes[1,1].set_title('T√§gliche Gesamtproduktion')
        axes[1,1].set_xlabel('Datum')
        axes[1,1].set_ylabel('Gesamtproduktion')
        axes[1,1].tick_params(axis='x', rotation=45)
        axes[1,1].grid(True, alpha=0.3)
    else:
        # Alternative: Produktion pro Maschine
        prod_by_machine = df_clean.groupby('Maschine')['Produktion'].mean()
        axes[1,1].pie(prod_by_machine.values, labels=prod_by_machine.index, autopct='%1.1f%%')
        axes[1,1].set_title('Produktionsverteilung pro Maschine')

    plt.tight_layout()
    plt.show()

    # Zus√§tzliche Statistiken
    print("\\nüìà Datenstatistiken:")
    print(f"  Gesamtproduktion: {df_clean['Produktion'].sum():,.0f} St√ºck")
    print(f"  Durchschnittsproduktion: {df_clean['Produktion'].mean():.0f} St√ºck/Tag")
    print(f"  Produktivste Maschine: {df_clean.groupby('Maschine')['Produktion'].mean().idxmax()}")
    print(f"  Temperaturbereich: {df_clean['Temperatur'].min():.1f}¬∞C bis {df_clean['Temperatur'].max():.1f}¬∞C")
    """

    # Ihre Implementierung:
    pass


def bonus_aufgabe_performance_vergleich():
    """
    BONUS AUFGABE: Performance-Vergleich (‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê)

    TODO: Erstellen Sie eine Studie, die verschiedene CSV-Import-Methoden vergleicht:
    1. Standard pd.read_csv()
    2. Chunked Reading
    3. Optimierte Datentypen
    4. Nur ben√∂tigte Spalten laden

    Messen Sie Ladezeit und Speicherverbrauch f√ºr jede Methode.
    """
    print("\n" + "=" * 50)
    print("üèÜ BONUS: Performance-Vergleich")
    print("=" * 50)

    # TODO: Implementieren Sie einen Performance-Vergleich verschiedener Import-Methoden

    # Ihre Implementierung hier...
    pass


def main():
    """
    Hauptfunktion - f√ºhrt alle √úbungen aus
    """
    print("üöÄ CSV Import √úbungen - Interaktives Lernmodul")
    print("=" * 60)

    # Testdaten vorbereiten
    test_dir = setup_test_data()

    print("\nüìö Verf√ºgbare √úbungen:")
    print("1. Grundlegender CSV-Import (‚≠ê‚≠ê‚òÜ‚òÜ)")
    print("2. Verschiedene Trennzeichen (‚≠ê‚≠ê‚òÜ‚òÜ)")
    print("3. Fehlende Werte behandeln (‚≠ê‚≠ê‚≠ê‚òÜ)")
    print("4. Datenvalidierung (‚≠ê‚≠ê‚≠ê‚≠ê)")
    print("5. Visualisierung (‚≠ê‚≠ê‚≠ê‚òÜ)")
    print("B. Bonus: Performance-Vergleich (‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê)")

    # Alle √úbungen durchf√ºhren (entkommentieren zum Aktivieren)
    """
    aufgabe_1_grundlegender_import()
    aufgabe_2_verschiedene_trennzeichen()
    aufgabe_3_fehlende_werte_behandeln()
    aufgabe_4_datenvalidierung()
    aufgabe_5_visualisierung()
    bonus_aufgabe_performance_vergleich()
    """

    print("\nüí° Hinweise zum L√∂sen der √úbungen:")
    print("  ‚Ä¢ Entkommentieren Sie die TODO-Bereiche")
    print("  ‚Ä¢ Ersetzen Sie 'pass' durch Ihren Code")
    print("  ‚Ä¢ Testen Sie jede Funktion einzeln")
    print("  ‚Ä¢ Die Musterl√∂sung ist als Kommentar verf√ºgbar")

    print("\nüéØ Lernziele erreichen:")
    print("  ‚úì CSV-Dateien sicher importieren")
    print("  ‚úì Verschiedene Formate handhaben")
    print("  ‚úì Datenqualit√§t sicherstellen")
    print("  ‚úì Probleme systematisch l√∂sen")


if __name__ == "__main__":
    main()
