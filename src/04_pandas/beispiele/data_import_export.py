#!/usr/bin/env python3
"""
Datenimport und -export - Pandas Tutorial f√ºr Bystronic

Dieses Beispiel demonstriert verschiedene Import/Export-M√∂glichkeiten:
- CSV-Dateien lesen und schreiben
- Excel-Dateien verarbeiten
- JSON-Daten handhaben
- Verschiedene Formatierungsoptionen

F√ºr Bystronic-Entwickler: Alternativen zu Excel-VBA f√ºr Datenverarbeitung
"""

import json
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd

print("=" * 60)
print("üìÅ PANDAS DATENIMPORT UND -EXPORT")
print("=" * 60)


# Beispieldaten erstellen f√ºr Demonstrationszwecke
def create_sample_data():
    """Erstelle Beispieldaten f√ºr verschiedene Export-Formate"""
    np.random.seed(42)

    # Produktionsdaten
    start_date = pd.Timestamp("2024-01-01")
    dates = pd.date_range(start_date, periods=30, freq="D")

    maschinen = ["Laser_01", "Laser_02", "Presse_01", "Presse_02", "Stanze_01"]
    schichten = ["Fr√ºh", "Sp√§t", "Nacht"]

    data = []
    for i, datum in enumerate(dates):
        for maschine in maschinen:
            for schicht in schichten:
                if np.random.random() > 0.1:  # 90% Wahrscheinlichkeit f√ºr Daten
                    data.append(
                        {
                            "Datum": datum.date(),
                            "Maschine": maschine,
                            "Schicht": schicht,
                            "Produktionszeit": round(np.random.uniform(6.0, 10.0), 2),
                            "St√ºckzahl": np.random.randint(50, 200),
                            "Ausschuss": round(np.random.uniform(0.01, 0.08), 4),
                            "Energieverbrauch": round(np.random.uniform(150, 300), 1),
                            "Temperatur": round(np.random.uniform(18.5, 24.5), 1),
                            "Wartung_erforderlich": np.random.choice(
                                [True, False], p=[0.1, 0.9]
                            ),
                        }
                    )

    return pd.DataFrame(data)


# 1. CSV-Dateien - Der Standard f√ºr Datenaustausch
print("\n1Ô∏è‚É£ CSV-Dateien verarbeiten")
print("-" * 40)

# Beispieldaten erstellen
df_produktion = create_sample_data()
print(f"Beispieldaten erstellt: {len(df_produktion)} Datens√§tze")
print(df_produktion.head())

# CSV schreiben (Standard)
csv_datei = "data/samples/produktionsdaten.csv"
df_produktion.to_csv(csv_datei, index=False)
print(f"\n‚úÖ CSV-Datei geschrieben: {csv_datei}")

# CSV lesen (Standard)
df_gelesen = pd.read_csv(csv_datei)
print(f"CSV-Datei gelesen: {len(df_gelesen)} Datens√§tze")
print("Datentypen nach CSV-Import:")
print(df_gelesen.dtypes)

# Problem: Datum als String importiert
print(f"\nDatum-Spalte Typ: {type(df_gelesen['Datum'].iloc[0])}")
print(f"Beispiel-Datum: {df_gelesen['Datum'].iloc[0]}")

# 2. CSV mit erweiterten Optionen
print("\n2Ô∏è‚É£ CSV mit erweiterten Optionen")
print("-" * 40)

# CSV mit deutschen Locale-Einstellungen
csv_deutsch = "produktionsdaten_deutsch.csv"
df_produktion.to_csv(
    csv_deutsch,
    index=False,
    sep=";",  # Semikolon als Trenner (Excel-Standard in Deutschland)
    decimal=",",  # Komma als Dezimaltrennzeichen
    encoding="utf-8",  # UTF-8 f√ºr Umlaute
    date_format="%d.%m.%Y",
)
print(f"‚úÖ Deutsche CSV-Datei geschrieben: {csv_deutsch}")

# CSV mit korrekten Datentypen lesen
df_korrekt = pd.read_csv(
    csv_deutsch,
    sep=";",
    decimal=",",
    encoding="utf-8",
    parse_dates=["Datum"],  # Automatische Datum-Konvertierung
    dtype={
        "Maschine": "string",
        "Schicht": "category",
        "Wartung_erforderlich": "boolean",
    },
)
print("Datentypen nach korrektem CSV-Import:")
print(df_korrekt.dtypes)
print(f"\nDatum-Spalte Typ: {type(df_korrekt['Datum'].iloc[0])}")

# 3. Excel-Dateien verarbeiten
print("\n3Ô∏è‚É£ Excel-Dateien verarbeiten")
print("-" * 40)

try:
    # Excel mit mehreren Arbeitsbl√§ttern erstellen
    excel_datei = "bystronic_daten.xlsx"

    # Verschiedene Datensets f√ºr verschiedene Bl√§tter
    df_maschinen = pd.DataFrame(
        {
            "Maschine": ["Laser_01", "Laser_02", "Presse_01", "Presse_02"],
            "Typ": ["ByStar", "ByStar", "Xpert", "Xpert"],
            "Standort": ["Halle A", "Halle A", "Halle B", "Halle B"],
            "Baujahr": [2019, 2020, 2018, 2021],
            "Anschaffung": [450000, 480000, 320000, 360000],
        }
    )

    # Monatliche Zusammenfassung
    df_monatlich = df_produktion.copy()
    df_monatlich["Monat"] = pd.to_datetime(df_monatlich["Datum"]).dt.to_period("M")
    df_zusammenfassung = (
        df_monatlich.groupby(["Monat", "Maschine"])
        .agg({"Produktionszeit": "sum", "St√ºckzahl": "sum", "Ausschuss": "mean"})
        .round(2)
        .reset_index()
    )

    # Excel mit mehreren Arbeitsbl√§ttern schreiben
    with pd.ExcelWriter(excel_datei, engine="openpyxl") as writer:
        df_produktion.head(100).to_excel(
            writer, sheet_name="Produktionsdaten", index=False
        )
        df_maschinen.to_excel(writer, sheet_name="Maschinen", index=False)
        df_zusammenfassung.to_excel(writer, sheet_name="Monatlich", index=False)

    print(f"‚úÖ Excel-Datei mit 3 Arbeitsbl√§ttern erstellt: {excel_datei}")

    # Excel-Datei lesen
    # Alle Arbeitsbl√§tter auflisten
    excel_file = pd.ExcelFile(excel_datei)
    print(f"Arbeitsbl√§tter in Excel: {excel_file.sheet_names}")

    # Bestimmtes Arbeitsblatt lesen
    df_maschinen_gelesen = pd.read_excel(excel_datei, sheet_name="Maschinen")
    print("Maschinendaten aus Excel:")
    print(df_maschinen_gelesen)

    # Mehrere Arbeitsbl√§tter gleichzeitig lesen
    excel_data = pd.read_excel(excel_datei, sheet_name=["Maschinen", "Monatlich"])
    print(f"Geladene Arbeitsbl√§tter: {list(excel_data.keys())}")

except ImportError:
    print("‚ùå F√ºr Excel-Support installieren: uv add openpyxl")
except Exception as e:
    print(f"Excel-Verarbeitung nicht verf√ºgbar: {e}")

# 4. JSON-Dateien verarbeiten
print("\n4Ô∏è‚É£ JSON-Dateien verarbeiten")
print("-" * 40)

# Strukturierte Daten f√ºr JSON
maschinendaten_json = {
    "unternehmen": "Bystronic",
    "standort": "Nieder√∂nz",
    "erstellt_am": str(datetime.now()),
    "maschinen": [
        {
            "id": "LASER_01",
            "typ": "ByStar Fiber 4020",
            "baujahr": 2019,
            "technische_daten": {
                "leistung": "6kW",
                "arbeitsbereich": "4000x2000mm",
                "max_blechdicke": "25mm",
            },
            "wartungshistorie": [
                {"datum": "2024-01-15", "typ": "Routinewartung", "dauer_h": 4},
                {"datum": "2024-02-20", "typ": "Reparatur", "dauer_h": 8},
            ],
            "produktionsdaten_ytd": {
                "betriebsstunden": 2450.5,
                "st√ºckzahl": 15678,
                "ausschussrate": 0.023,
            },
        },
        {
            "id": "PRESSE_01",
            "typ": "Xpert 150",
            "baujahr": 2018,
            "technische_daten": {
                "presskraft": "150t",
                "arbeitsbereich": "3000x1500mm",
                "max_blechdicke": "10mm",
            },
            "wartungshistorie": [
                {"datum": "2024-01-10", "typ": "Routinewartung", "dauer_h": 6}
            ],
            "produktionsdaten_ytd": {
                "betriebsstunden": 3200.8,
                "st√ºckzahl": 8934,
                "ausschussrate": 0.045,
            },
        },
    ],
}

# JSON schreiben
json_datei = "maschinendaten.json"
with open(json_datei, "w", encoding="utf-8") as f:
    json.dump(maschinendaten_json, f, indent=2, ensure_ascii=False)
print(f"‚úÖ JSON-Datei geschrieben: {json_datei}")

# JSON lesen und in DataFrame konvertieren
with open(json_datei, encoding="utf-8") as f:
    daten = json.load(f)

# Maschinen-Grunddaten extrahieren
maschinen_liste = []
for maschine in daten["maschinen"]:
    maschinen_liste.append(
        {
            "ID": maschine["id"],
            "Typ": maschine["typ"],
            "Baujahr": maschine["baujahr"],
            "Betriebsstunden": maschine["produktionsdaten_ytd"]["betriebsstunden"],
            "St√ºckzahl": maschine["produktionsdaten_ytd"]["st√ºckzahl"],
            "Ausschussrate": maschine["produktionsdaten_ytd"]["ausschussrate"],
        }
    )

df_aus_json = pd.DataFrame(maschinen_liste)
print("DataFrame aus JSON erstellt:")
print(df_aus_json)

# 5. Pandas JSON-Funktionen
print("\n5Ô∏è‚É£ Pandas JSON-Funktionen")
print("-" * 40)

# DataFrame direkt zu JSON
df_sample = df_produktion.head(5)
json_string = df_sample.to_json(orient="records", date_format="iso")
print("DataFrame als JSON (erste 5 Zeilen, gek√ºrzt):")
print(json_string[:200] + "...")

# JSON zur√ºck zu DataFrame
df_from_json_string = pd.read_json(json_string, orient="records")
print("DataFrame aus JSON-String wiederhergestellt:")
print(df_from_json_string)

# 6. Datenbereinigung beim Import
print("\n6Ô∏è‚É£ Datenbereinigung beim Import")
print("-" * 40)

# CSV mit "schmutzigen" Daten erstellen
schmutzige_daten = pd.DataFrame(
    {
        "Maschine": ["Laser_01", "  Presse_01  ", "STANZE_01", None, "Laser_02"],
        "Produktionszeit": ["8.5", "  7.2  ", "invalid", "9.1", "6.8"],
        "Datum": ["2024-01-01", "01.02.2024", "2024/03/01", "2024-04-01", None],
        "Status": ["OK", "ok", "OK", "Fehler", "OK"],
    }
)

schmutzige_csv = "schmutzige_daten.csv"
schmutzige_daten.to_csv(schmutzige_csv, index=False)
print("Schmutzige Daten erstellt:")
print(schmutzige_daten)

# Daten mit Bereinigung lesen
df_bereinigt = pd.read_csv(schmutzige_csv)

# Bereinigungsschritte
print("\nBereinigung der Daten:")

# Whitespace entfernen
df_bereinigt["Maschine"] = df_bereinigt["Maschine"].str.strip()
print("1. Whitespace entfernt")

# Gross-/Kleinschreibung normalisieren
df_bereinigt["Maschine"] = df_bereinigt["Maschine"].str.title()
print("2. Gross-/Kleinschreibung normalisiert")

# Numerische Werte bereinigen
df_bereinigt["Produktionszeit"] = pd.to_numeric(
    df_bereinigt["Produktionszeit"].str.strip(),
    errors="coerce",  # Ung√ºltige Werte werden zu NaN
)
print("3. Numerische Werte bereinigt")

# Status normalisieren
df_bereinigt["Status"] = df_bereinigt["Status"].str.upper()
print("4. Status normalisiert")

print("Bereinigte Daten:")
print(df_bereinigt)
print(f"Fehlende Werte: {df_bereinigt.isnull().sum().sum()}")

# 7. Grosse Dateien effizient verarbeiten
print("\n7Ô∏è‚É£ Grosse Dateien effizient verarbeiten")
print("-" * 40)

# Chunked Reading f√ºr grosse CSV-Dateien
chunk_size = 50  # In der Praxis: 10000 oder mehr
total_rows = 0
produktionszeit_sum = 0

print(f"Verarbeite CSV in Chunks √† {chunk_size} Zeilen:")
for chunk in pd.read_csv("data/samples/produktionsdaten.csv", chunksize=chunk_size):
    total_rows += len(chunk)
    produktionszeit_sum += chunk["Produktionszeit"].sum()
    print(f"  Chunk verarbeitet: {len(chunk)} Zeilen")

print(f"Insgesamt {total_rows} Zeilen verarbeitet")
print(f"Gesamte Produktionszeit: {produktionszeit_sum:.2f} Stunden")

# 8. Datenvalidierung beim Import
print("\n8Ô∏è‚É£ Datenvalidierung beim Import")
print("-" * 40)


def validate_production_data(df):
    """Validiert Produktionsdaten nach Bystronic-Standards"""
    errors = []

    # Pflichtfelder pr√ºfen
    required_columns = ["Datum", "Maschine", "Schicht", "Produktionszeit"]
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        errors.append(f"Fehlende Spalten: {missing_columns}")

    # Datentypen pr√ºfen
    if "Produktionszeit" in df.columns:
        if not pd.api.types.is_numeric_dtype(df["Produktionszeit"]):
            errors.append("Produktionszeit muss numerisch sein")
        elif (df["Produktionszeit"] < 0).any():
            errors.append("Produktionszeit kann nicht negativ sein")
        elif (df["Produktionszeit"] > 24).any():
            errors.append("Produktionszeit kann nicht √ºber 24h sein")

    # Gesch√§ftsregeln pr√ºfen
    if "Ausschuss" in df.columns:
        if (df["Ausschuss"] < 0).any() or (df["Ausschuss"] > 1).any():
            errors.append("Ausschussrate muss zwischen 0 und 1 liegen")

    return errors


# Validation testen
validation_errors = validate_production_data(df_produktion)
if validation_errors:
    print("‚ùå Validierungsfehler gefunden:")
    for error in validation_errors:
        print(f"  ‚Ä¢ {error}")
else:
    print("‚úÖ Alle Validierungspr√ºfungen bestanden")

# 9. Export mit Formatierung
print("\n9Ô∏è‚É£ Export mit Formatierung")
print("-" * 40)

# Zusammenfassung f√ºr Export erstellen
export_df = (
    df_produktion.groupby(["Maschine"])
    .agg({"Produktionszeit": ["sum", "mean"], "St√ºckzahl": "sum", "Ausschuss": "mean"})
    .round(2)
)

# Spalten flach machen
export_df.columns = ["_".join(col).strip() for col in export_df.columns]
export_df = export_df.reset_index()

print("Export-DataFrame erstellt:")
print(export_df.head())

# CSV mit deutscher Formatierung exportieren
export_csv = "export_zusammenfassung.csv"
export_df.to_csv(
    export_csv,
    index=False,
    sep=";",
    decimal=",",
    encoding="utf-8-sig",  # BOM f√ºr Excel-Kompatibilit√§t
    float_format="%.2f",
)
print(f"‚úÖ Formatierte CSV-Datei exportiert: {export_csv}")

# Aufr√§umen - Tempor√§re Dateien l√∂schen (optional)
temp_files = [
    "data/generated/produktionsdaten.csv",
    "data/generated/produktionsdaten_deutsch.csv",
    "data/generated/maschinendaten.json",
    "data/generated/schmutzige_daten.csv",
    "export_zusammenfassung.csv",
]

print("\nüßπ Tempor√§re Dateien erstellt (werden von .gitignore ignoriert):")
for file in temp_files:
    if Path(file).exists():
        print(f"  ‚Ä¢ {file}")

print("\n" + "=" * 60)
print("üéØ ZUSAMMENFASSUNG: DATENIMPORT UND -EXPORT")
print("=" * 60)
print("‚úÖ CSV-Dateien mit verschiedenen Optionen")
print("‚úÖ Excel-Dateien mit mehreren Arbeitsbl√§ttern")
print("‚úÖ JSON-Daten strukturiert verarbeiten")
print("‚úÖ Datenbereinigung beim Import")
print("‚úÖ Chunked Reading f√ºr grosse Dateien")
print("‚úÖ Datenvalidierung implementieren")
print("‚úÖ Formatierter Export f√ºr verschiedene Systeme")
print("\nüí° Als Bystronic-Entwickler k√∂nnen Sie jetzt alle g√§ngigen")
print("   Datenformate effizient mit Pandas verarbeiten!")
print("   N√§chster Schritt: Datenbereinigung und -validierung")
